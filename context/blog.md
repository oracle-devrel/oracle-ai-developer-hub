Building a Generative AI assistant on Oracle Cloud Infrastructure(OCI) with Oracle JET
with Bogdan Farca and John "JB" Brock (aka. peppertech)
Conceptual evolution of human-computer interactionInitial interactions with devices relied on command-line interfaces, which required users to remember specific syntax. This changed with the advent of Graphical User Interfaces (GUIs), simplifying interactions to point-and-click operations. Users had to manually direct each action using mouse clicks and keyboard inputs.
The introduction of touchscreens marked a significant leap, allowing for more natural gestures like swiping, tapping, and pinch-to-zoom. Similarly, speech recognition technology evolved, enabling voice commands and basic conversational interactions, although it required users to speak slowly and clearly.
Recently, the field of artificial intelligence (AI) has seen remarkable progress, particularly with the emergence of generative AI (GenAI). GenAI technologies have the unique capability to create new and innovative content, including text, code, images, and more, based on general instructions.
We can all agree that overall trend is to shift from users adapting to rigid computer systems, to systems adapting to understand human behaviours.
In this blog post, we will explore the development of a GenAI assistant, highlighting contemporary practices in application development.
The Data-Model-Service (DMS) Architecture
The architecture of the LLM-based application is composed of three integral layers, each serving a distinct but interconnected function:
Data Layer: The Data Layer serves as the cornerstone of the assistant's architecture, tasked with the crucial role of storing and managing a diverse array of data that is vital for the assistant's functionality. The nature of this data - its quality, structure, and availability - plays a pivotal role in shaping the design and development strategies for the subsequent layers. This layer not only acts as a repository but also influences how the assistant processes and responds to queries, making it a critical component in the overall system.
Model Layer: At the heart of the assistant lies the Model layer, which houses the advanced AI models that power the generation of new content. These models are sophisticated and can be trained on various data sources, including textual documents, code repositories, and visual images. This training equips the models with the ability to produce accurate and relevant outputs based on user queries and instructions. Key tasks in this layer include parsing and segmenting data for easier processing, as well as crafting the correct prompts or fine-tuning the Large Language Models (LLMs) for specific needs.
Service Layer: The Service layer acts as the interface between the assistant and external applications. It offers a suite of Application Programming Interfaces (APIs) that enable other software to communicate with the assistant. These APIs facilitate a range of interactions, such as querying the assistant for specific information, requesting the generation of new content, or executing other specialized tasks. This layer is crucial for integrating the assistant into broader systems and workflows, allowing for seamless interaction and functionality enhancement.

Advantages
The Data-Model-Service (DMS) architecture introduces a holistic approach to the design and implementation of large language model (LLM)-based applications. One of the key benefits of this architecture lies in its modularity, as the distinct layers - Data, Model, and Service - provide clear separation of concerns, enabling efficient development, maintenance, and scalability.
The Data Layer ensures that the assistant has a robust foundation by managing diverse data types, influencing the subsequent layers' strategies. This modular design also facilitates flexibility, allowing organizations to adapt and extend the system based on evolving requirements without significant disruptions.
Furthermore, the Model Layer introduces a powerful capability to the architecture by incorporating advanced AI models that can be trained on diverse data sources. This flexibility in training allows the assistant to cater to a wide range of user needs, from processing textual information to interpreting visual content. The parsing and segmentation of data within this layer contribute to the model's efficiency, making it adept at generating accurate and contextually relevant outputs. The use of Large Language Models (LLMs) enhances the model's adaptability and performance, making it well-suited for various applications, including natural language understanding, content generation, and knowledge synthesis.
The Service Layer, acting as the interface to external applications through a suite of APIs, further extends the utility of the DMS architecture. By facilitating seamless communication between the assistant and other software systems, this layer enables integration into diverse workflows and environments. The ability to query the assistant for specific information, request content generation, and perform specialized tasks enhances the overall versatility of the LLM-based application. As a result, the DMS architecture not only provides a comprehensive and efficient framework for developing language-based applications but also opens up new possibilities for collaboration and integration in the broader field of artificial intelligence and information systems.
What we will build
In this comprehensive three-part article series, we aim to demystify the process of creating a chatbot that is powered by your proprietary data, leveraging the robust capabilities of Oracle Cloud as the foundational infrastructure. Our goal is to guide you through each step, ensuring that even those with minimal experience in chatbot development can follow along and achieve a functional and intelligent chatbot by the end of this series.
Part 1: The article you're reading now
Introducing the DMS model / architecture.
Part 2: Crafting the Data and Model Layers
The foundation of any chatbot is its data layer, which in our case, will be a straightforward Frequently Asked Questions (FAQ) file. This file will be meticulously parsed and then loaded into an in-memory array for quick access and retrieval. We will employ a basic chunking technique where each 'chunk' is composed of a pair: one question and its corresponding answer. This method is particularly effective for simple datasets.
However, we recognize that as datasets grow in complexity, the chunking methods must evolve to handle the intricacies. For those dealing with more sophisticated data structures, the chunking process will become more elaborate. Rest assured, any modifications required to handle such complexity will be confined to the data layer, ensuring a clean separation of concerns.
At the heart of our chatbot is the Model layer, which utilizes Oracle's latest Generative AI services. These services are built upon the Cohere base model, known for its powerful language understanding and generation capabilities. The Model layer's primary function is to process user input and generate appropriate responses.
We will expose the functionality of this layer through a well-defined Application Programming Interface (API), which abstracts the underlying complexity and allows for seamless integration with other system components. This decoupling is crucial as it provides the flexibility to modify or replace the Model layer without impacting the Service layer or the user experience.
Part 3: Developing the User Interface with Oracle JET
The final installment of our series focuses on the user interface (UI), the layer with which end-users directly interact. For the construction of the UI, we will utilize Oracle JavaScript Extension Toolkit (JET), a quite powerful toolkit that enables developers to build client-side applications in a fast and efficient manner.
Oracle JET is designed with enterprise applications in mind, offering a collection of modular and reusable components that make it straightforward to create a professional-looking frontend. We will guide you through the process of using Oracle JET to construct a user-friendly chat interface that connects to our Service layer, ensuring a seamless and engaging user experience.
By the end of this series, you will have a clear understanding of how to build a chatbot from the ground up, with a robust data layer, an intelligent model layer, and an interactive user interface - all hosted on the reliable Oracle Cloud infrastructure. Whether you're looking to implement a chatbot for customer service, internal use, or any other application, this series will equip you with the knowledge and tools to make it a reality.