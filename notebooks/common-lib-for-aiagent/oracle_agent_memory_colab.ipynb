{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce71dba9",
   "metadata": {},
   "source": [
    "# Oracle Database Memory Store for AI Agents\n",
    "\n",
    "This notebook demonstrates a production-ready memory store using Oracle Database for AI agents with LangChain integration.\n",
    "\n",
    "## Features\n",
    "- **LangChain SQLChatMessageHistory** for conversation persistence\n",
    "- **LangChain SQL Database agent** for querying\n",
    "- **Vector embeddings** with Oracle Vector Store\n",
    "- **Full LangChain memory integration**\n",
    "- Entity tracking and session management\n",
    "- Task execution records\n",
    "- Agent state management\n",
    "\n",
    "## Overview\n",
    "This implementation provides a robust memory system for AI agents using Oracle Database as the backend, enabling:\n",
    "- Persistent conversation history\n",
    "- Entity extraction and tracking\n",
    "- Task execution records\n",
    "- Vector embeddings for semantic search\n",
    "- Integration with LangChain agents and chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aabb5b8",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies\n",
    "\n",
    "Run the cell below to install all required packages for Google Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install required packages for Google Colab\n",
    "packages_to_install = [\n",
    "    \"sqlalchemy>=2.0.0\",\n",
    "    \"oracledb>=1.4.0\",\n",
    "    \"langchain>=0.0.300\",\n",
    "    \"langchain-community>=0.0.10\",\n",
    "    \"python-dotenv>=1.0.0\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in packages_to_install:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    \n",
    "print(\"✓ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e0009f",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1581c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, Column, String, Text, DateTime, Integer, Index, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, Session\n",
    "\n",
    "from langchain.memory import BaseMemory, ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain.chat_history import BaseChatMessageHistory\n",
    "from langchain.schema import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.llms.base import BaseLanguageModel\n",
    "from langchain.embeddings.base import Embeddings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207bdcc",
   "metadata": {},
   "source": [
    "## 3. Define Oracle Database Models\n",
    "\n",
    "SQLAlchemy ORM models for storing:\n",
    "- **ConversationMemory**: Agent conversation history\n",
    "- **EntityMemory**: Extracted entities and facts\n",
    "- **AgentTask**: Task execution records\n",
    "- **VectorEmbedding**: Vector embeddings for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad995fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Oracle Database Models (SQLAlchemy ORM)\n",
    "# ============================================================================\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class ConversationMemory(Base):\n",
    "    \"\"\"Stores conversation history in Oracle database\"\"\"\n",
    "    __tablename__ = \"agent_conversation_memory\"\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    session_id = Column(String(255), nullable=False, index=True)\n",
    "    agent_id = Column(String(255), nullable=False, index=True)\n",
    "    message_type = Column(String(50), nullable=False)  # 'human' or 'ai'\n",
    "    content = Column(Text, nullable=False)\n",
    "    metadata = Column(Text)  # JSON string\n",
    "    created_at = Column(DateTime, default=datetime.utcnow, index=True)\n",
    "    \n",
    "    __table_args__ = (\n",
    "        Index('idx_session_agent_created', 'session_id', 'agent_id', 'created_at'),\n",
    "    )\n",
    "    \n",
    "    def to_message(self) -> BaseMessage:\n",
    "        \"\"\"Convert DB record to LangChain message\"\"\"\n",
    "        if self.message_type == \"human\":\n",
    "            return HumanMessage(content=self.content)\n",
    "        else:\n",
    "            return AIMessage(content=self.content)\n",
    "\n",
    "\n",
    "class EntityMemory(Base):\n",
    "    \"\"\"Stores extracted entities and facts for agent reasoning\"\"\"\n",
    "    __tablename__ = \"agent_entity_memory\"\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    session_id = Column(String(255), nullable=False, index=True)\n",
    "    agent_id = Column(String(255), nullable=False, index=True)\n",
    "    entity_type = Column(String(100), nullable=False)  # 'person', 'location', etc.\n",
    "    entity_name = Column(String(255), nullable=False)\n",
    "    entity_value = Column(Text, nullable=False)  # JSON string for complex data\n",
    "    last_mentioned = Column(DateTime, default=datetime.utcnow)\n",
    "    mention_count = Column(Integer, default=1)\n",
    "    \n",
    "    __table_args__ = (\n",
    "        Index('idx_session_entity_type', 'session_id', 'agent_id', 'entity_type'),\n",
    "        Index('idx_entity_name', 'entity_name'),\n",
    "    )\n",
    "\n",
    "\n",
    "class AgentTask(Base):\n",
    "    \"\"\"Stores agent tasks and execution history\"\"\"\n",
    "    __tablename__ = \"agent_tasks\"\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    session_id = Column(String(255), nullable=False, index=True)\n",
    "    agent_id = Column(String(255), nullable=False, index=True)\n",
    "    task_description = Column(Text, nullable=False)\n",
    "    status = Column(String(50), default=\"pending\")  # pending, in_progress, completed, failed\n",
    "    result = Column(Text)  # JSON string\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    completed_at = Column(DateTime)\n",
    "    \n",
    "    __table_args__ = (\n",
    "        Index('idx_session_status', 'session_id', 'status'),\n",
    "    )\n",
    "\n",
    "\n",
    "class VectorEmbedding(Base):\n",
    "    \"\"\"Stores vector embeddings for semantic search\"\"\"\n",
    "    __tablename__ = \"agent_vector_embeddings\"\n",
    "    \n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    session_id = Column(String(255), nullable=False, index=True)\n",
    "    agent_id = Column(String(255), nullable=False, index=True)\n",
    "    content = Column(Text, nullable=False)\n",
    "    embedding = Column(Text, nullable=False)  # JSON array as string\n",
    "    metadata = Column(Text)  # JSON string with source, type, etc.\n",
    "    created_at = Column(DateTime, default=datetime.utcnow)\n",
    "    \n",
    "    __table_args__ = (\n",
    "        Index('idx_session_vector', 'session_id', 'agent_id'),\n",
    "    )\n",
    "\n",
    "print(\"✓ Database models defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64cd7bf",
   "metadata": {},
   "source": [
    "## 4. LangChain Chat Message History Implementation\n",
    "\n",
    "Define the LangChain-compatible chat message history using Oracle database backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LangChain Chat Message History\n",
    "# ============================================================================\n",
    "\n",
    "class OracleSQLChatMessageHistory(BaseChatMessageHistory):\n",
    "    \"\"\"\n",
    "    LangChain-compatible chat message history using Oracle database.\n",
    "    Implements the BaseChatMessageHistory interface from LangChain.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        engine: sa.engine.Engine,\n",
    "        session_id: str,\n",
    "        agent_id: str = \"default_agent\",\n",
    "    ):\n",
    "        \"\"\"Initialize Oracle chat message history\"\"\"\n",
    "        self.engine = engine\n",
    "        self.session_id = session_id\n",
    "        self.agent_id = agent_id\n",
    "        self.SessionLocal = sessionmaker(bind=engine)\n",
    "    \n",
    "    @property\n",
    "    def messages(self) -> List[BaseMessage]:\n",
    "        \"\"\"Get all messages from Oracle\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            records = session.query(ConversationMemory).filter(\n",
    "                ConversationMemory.session_id == self.session_id,\n",
    "                ConversationMemory.agent_id == self.agent_id,\n",
    "            ).order_by(ConversationMemory.created_at).all()\n",
    "            \n",
    "            return [msg.to_message() for msg in records]\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def add_message(self, message: BaseMessage) -> None:\n",
    "        \"\"\"Add a message to Oracle\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            if isinstance(message, HumanMessage):\n",
    "                msg_type = \"human\"\n",
    "            elif isinstance(message, AIMessage):\n",
    "                msg_type = \"ai\"\n",
    "            else:\n",
    "                msg_type = \"system\"\n",
    "            \n",
    "            db_msg = ConversationMemory(\n",
    "                session_id=self.session_id,\n",
    "                agent_id=self.agent_id,\n",
    "                message_type=msg_type,\n",
    "                content=message.content,\n",
    "            )\n",
    "            session.add(db_msg)\n",
    "            session.commit()\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear all messages for this session\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            session.query(ConversationMemory).filter(\n",
    "                ConversationMemory.session_id == self.session_id,\n",
    "                ConversationMemory.agent_id == self.agent_id,\n",
    "            ).delete()\n",
    "            session.commit()\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "print(\"✓ LangChain Chat Message History defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dd693f",
   "metadata": {},
   "source": [
    "## 5. Oracle Connection Configuration\n",
    "\n",
    "Define configuration class for Oracle database connection with support for both service names and SIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ba9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Oracle Connection Configuration\n",
    "# ============================================================================\n",
    "\n",
    "class OracleMemoryConfig:\n",
    "    \"\"\"Configuration for Oracle memory store and LangChain integration\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        username: str,\n",
    "        password: str,\n",
    "        host: str,\n",
    "        port: int = 1521,\n",
    "        service_name: Optional[str] = None,\n",
    "        sid: Optional[str] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize Oracle connection configuration.\n",
    "        \n",
    "        Args:\n",
    "            username: Oracle username\n",
    "            password: Oracle password\n",
    "            host: Oracle host address\n",
    "            port: Oracle port (default 1521)\n",
    "            service_name: Oracle service name (for Oracle Cloud/modern setup)\n",
    "            sid: Oracle SID (for on-premise traditional setup)\n",
    "        \"\"\"\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.service_name = service_name\n",
    "        self.sid = sid\n",
    "        \n",
    "        if not service_name and not sid:\n",
    "            raise ValueError(\"Either service_name or sid must be provided\")\n",
    "    \n",
    "    def get_connection_string(self) -> str:\n",
    "        \"\"\"Generate Oracle connection string for SQLAlchemy\"\"\"\n",
    "        if self.service_name:\n",
    "            # Oracle Cloud or modern setup\n",
    "            dsn = f\"{self.host}:{self.port}/{self.service_name}\"\n",
    "            return f\"oracle+oracledb://{self.username}:{self.password}@{dsn}\"\n",
    "        else:\n",
    "            # Traditional setup with SID\n",
    "            dsn = f\"{self.host}:{self.port}:{self.sid}\"\n",
    "            return f\"oracle+oracledb://{self.username}:{self.password}@{dsn}\"\n",
    "\n",
    "print(\"✓ Oracle Configuration class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559f2c90",
   "metadata": {},
   "source": [
    "## 6. Oracle Agent Memory Implementation\n",
    "\n",
    "Complete implementation of LangChain-compatible memory store using Oracle database with full support for conversation history, entity management, and vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ec566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Oracle Memory Store Implementation\n",
    "# ============================================================================\n",
    "\n",
    "class OracleAgentMemory(BaseMemory):\n",
    "    \"\"\"\n",
    "    LangChain-compatible memory store using Oracle database.\n",
    "    \n",
    "    Provides persistent storage for:\n",
    "    - Conversation history\n",
    "    - Entity extraction and tracking\n",
    "    - Task execution records\n",
    "    - Agent state management\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        engine: sa.engine.Engine,\n",
    "        session_id: str,\n",
    "        agent_id: str = \"default_agent\",\n",
    "        max_context_length: int = 10,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize Oracle agent memory.\n",
    "        \n",
    "        Args:\n",
    "            engine: SQLAlchemy engine for Oracle\n",
    "            session_id: Unique conversation session ID\n",
    "            agent_id: Agent identifier\n",
    "            max_context_length: Max messages to retrieve for context window\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.engine = engine\n",
    "        self.session_id = session_id\n",
    "        self.agent_id = agent_id\n",
    "        self.max_context_length = max_context_length\n",
    "        self.SessionLocal = sessionmaker(bind=engine)\n",
    "    \n",
    "    @property\n",
    "    def memory_variables(self) -> List[str]:\n",
    "        \"\"\"Return memory variable names for LangChain\"\"\"\n",
    "        return [\"history\"]\n",
    "    \n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Retrieve conversation history from Oracle\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            messages = session.query(ConversationMemory).filter(\n",
    "                ConversationMemory.session_id == self.session_id,\n",
    "                ConversationMemory.agent_id == self.agent_id,\n",
    "            ).order_by(ConversationMemory.created_at).limit(\n",
    "                self.max_context_length\n",
    "            ).all()\n",
    "            \n",
    "            history = \"\\n\".join([\n",
    "                f\"{msg.message_type.upper()}: {msg.content}\" \n",
    "                for msg in messages\n",
    "            ])\n",
    "            return {\"history\": history}\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"Save user input and AI response to Oracle\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            # Save user message\n",
    "            if \"input\" in inputs:\n",
    "                user_msg = ConversationMemory(\n",
    "                    session_id=self.session_id,\n",
    "                    agent_id=self.agent_id,\n",
    "                    message_type=\"human\",\n",
    "                    content=inputs[\"input\"],\n",
    "                    metadata=json.dumps({\"type\": \"user_input\"})\n",
    "                )\n",
    "                session.add(user_msg)\n",
    "            \n",
    "            # Save AI response\n",
    "            if \"output\" in outputs:\n",
    "                ai_msg = ConversationMemory(\n",
    "                    session_id=self.session_id,\n",
    "                    agent_id=self.agent_id,\n",
    "                    message_type=\"ai\",\n",
    "                    content=outputs[\"output\"],\n",
    "                    metadata=json.dumps({\"type\": \"agent_response\"})\n",
    "                )\n",
    "                session.add(ai_msg)\n",
    "            \n",
    "            session.commit()\n",
    "        except Exception as e:\n",
    "            session.rollback()\n",
    "            raise Exception(f\"Error saving context to Oracle: {e}\")\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear all conversation history for this session\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            session.query(ConversationMemory).filter(\n",
    "                ConversationMemory.session_id == self.session_id,\n",
    "                ConversationMemory.agent_id == self.agent_id,\n",
    "            ).delete()\n",
    "            session.commit()\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def add_entity(self, entity_type: str, entity_name: str, entity_value: Dict) -> None:\n",
    "        \"\"\"Store extracted entity in Oracle\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            existing = session.query(EntityMemory).filter(\n",
    "                EntityMemory.session_id == self.session_id,\n",
    "                EntityMemory.agent_id == self.agent_id,\n",
    "                EntityMemory.entity_type == entity_type,\n",
    "                EntityMemory.entity_name == entity_name,\n",
    "            ).first()\n",
    "            \n",
    "            if existing:\n",
    "                existing.entity_value = json.dumps(entity_value)\n",
    "                existing.last_mentioned = datetime.utcnow()\n",
    "                existing.mention_count += 1\n",
    "            else:\n",
    "                entity = EntityMemory(\n",
    "                    session_id=self.session_id,\n",
    "                    agent_id=self.agent_id,\n",
    "                    entity_type=entity_type,\n",
    "                    entity_name=entity_name,\n",
    "                    entity_value=json.dumps(entity_value),\n",
    "                )\n",
    "                session.add(entity)\n",
    "            \n",
    "            session.commit()\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_entities(self, entity_type: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Retrieve stored entities from Oracle\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            query = session.query(EntityMemory).filter(\n",
    "                EntityMemory.session_id == self.session_id,\n",
    "                EntityMemory.agent_id == self.agent_id,\n",
    "            )\n",
    "            \n",
    "            if entity_type:\n",
    "                query = query.filter(EntityMemory.entity_type == entity_type)\n",
    "            \n",
    "            entities = []\n",
    "            for e in query.all():\n",
    "                entities.append({\n",
    "                    \"type\": e.entity_type,\n",
    "                    \"name\": e.entity_name,\n",
    "                    \"value\": json.loads(e.entity_value),\n",
    "                    \"mention_count\": e.mention_count,\n",
    "                    \"last_mentioned\": e.last_mentioned.isoformat(),\n",
    "                })\n",
    "            \n",
    "            return entities\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def add_task(self, task_description: str, result: Optional[Dict] = None) -> int:\n",
    "        \"\"\"Record a task or action taken by the agent\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            task = AgentTask(\n",
    "                session_id=self.session_id,\n",
    "                agent_id=self.agent_id,\n",
    "                task_description=task_description,\n",
    "                status=\"in_progress\",\n",
    "                result=json.dumps(result) if result else None,\n",
    "            )\n",
    "            session.add(task)\n",
    "            session.commit()\n",
    "            return task.id\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def update_task_status(self, task_id: int, status: str, result: Optional[Dict] = None) -> None:\n",
    "        \"\"\"Update task status and result\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            task = session.query(AgentTask).filter(AgentTask.id == task_id).first()\n",
    "            if task:\n",
    "                task.status = status\n",
    "                if result:\n",
    "                    task.result = json.dumps(result)\n",
    "                if status == \"completed\":\n",
    "                    task.completed_at = datetime.utcnow()\n",
    "                session.commit()\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_conversation_history(self, limit: Optional[int] = None) -> List[Dict]:\n",
    "        \"\"\"Get complete conversation history for this session\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            query = session.query(ConversationMemory).filter(\n",
    "                ConversationMemory.session_id == self.session_id,\n",
    "                ConversationMemory.agent_id == self.agent_id,\n",
    "            ).order_by(ConversationMemory.created_at)\n",
    "            \n",
    "            if limit:\n",
    "                query = query.limit(limit)\n",
    "            \n",
    "            history = []\n",
    "            for msg in query.all():\n",
    "                history.append({\n",
    "                    \"id\": msg.id,\n",
    "                    \"type\": msg.message_type,\n",
    "                    \"content\": msg.content,\n",
    "                    \"created_at\": msg.created_at.isoformat(),\n",
    "                    \"metadata\": json.loads(msg.metadata) if msg.metadata else {},\n",
    "                })\n",
    "            \n",
    "            return history\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_chat_message_history(self) -> OracleSQLChatMessageHistory:\n",
    "        \"\"\"Get LangChain-compatible chat message history\"\"\"\n",
    "        return OracleSQLChatMessageHistory(\n",
    "            engine=self.engine,\n",
    "            session_id=self.session_id,\n",
    "            agent_id=self.agent_id\n",
    "        )\n",
    "    \n",
    "    def add_embedding(self, content: str, embedding: List[float], metadata: Optional[Dict] = None) -> None:\n",
    "        \"\"\"Store vector embedding for semantic search\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            vector_record = VectorEmbedding(\n",
    "                session_id=self.session_id,\n",
    "                agent_id=self.agent_id,\n",
    "                content=content,\n",
    "                embedding=json.dumps(embedding),\n",
    "                metadata=json.dumps(metadata) if metadata else None,\n",
    "            )\n",
    "            session.add(vector_record)\n",
    "            session.commit()\n",
    "        finally:\n",
    "            session.close()\n",
    "    \n",
    "    def get_embeddings(self, limit: Optional[int] = None) -> List[Dict]:\n",
    "        \"\"\"Retrieve stored embeddings for semantic search\"\"\"\n",
    "        session = self.SessionLocal()\n",
    "        try:\n",
    "            query = session.query(VectorEmbedding).filter(\n",
    "                VectorEmbedding.session_id == self.session_id,\n",
    "                VectorEmbedding.agent_id == self.agent_id,\n",
    "            ).order_by(VectorEmbedding.created_at)\n",
    "            \n",
    "            if limit:\n",
    "                query = query.limit(limit)\n",
    "            \n",
    "            embeddings = []\n",
    "            for record in query.all():\n",
    "                embeddings.append({\n",
    "                    \"id\": record.id,\n",
    "                    \"content\": record.content,\n",
    "                    \"embedding\": json.loads(record.embedding),\n",
    "                    \"metadata\": json.loads(record.metadata) if record.metadata else {},\n",
    "                    \"created_at\": record.created_at.isoformat(),\n",
    "                })\n",
    "            \n",
    "            return embeddings\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "print(\"✓ Oracle Agent Memory class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507031d7",
   "metadata": {},
   "source": [
    "## 7. LangChain Agent Builders\n",
    "\n",
    "Helper classes for creating LangChain SQL agents and memory chains with Oracle backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LangChain Agent Builders\n",
    "# ============================================================================\n",
    "\n",
    "class OracleSQLAgentBuilder:\n",
    "    \"\"\"Builder for creating LangChain SQL agents with Oracle database\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_sql_agent(\n",
    "        oracle_config: OracleMemoryConfig,\n",
    "        llm: BaseLanguageModel,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        \"\"\"Create a LangChain SQL agent for Oracle database queries\"\"\"\n",
    "        engine = create_engine(oracle_config.get_connection_string())\n",
    "        db = SQLDatabase(engine)\n",
    "        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "        \n",
    "        agent = create_sql_agent(\n",
    "            llm=llm,\n",
    "            toolkit=toolkit,\n",
    "            verbose=verbose,\n",
    "            agent_type=\"openai-tools\",\n",
    "        )\n",
    "        \n",
    "        return agent\n",
    "\n",
    "\n",
    "class OracleLangChainMemoryBuilder:\n",
    "    \"\"\"Builder for creating LangChain memory chains with Oracle\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_conversation_memory(\n",
    "        oracle_config: OracleMemoryConfig,\n",
    "        session_id: str,\n",
    "        agent_id: str = \"default_agent\",\n",
    "        llm: Optional[BaseLanguageModel] = None,\n",
    "    ) -> ConversationBufferMemory:\n",
    "        \"\"\"Create LangChain ConversationBufferMemory with Oracle backend\"\"\"\n",
    "        memory = create_oracle_agent_memory(\n",
    "            oracle_config=oracle_config,\n",
    "            session_id=session_id,\n",
    "            agent_id=agent_id\n",
    "        )\n",
    "        \n",
    "        return ConversationBufferMemory(\n",
    "            chat_memory=memory.get_chat_message_history(),\n",
    "            return_messages=True\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_conversation_summary_memory(\n",
    "        oracle_config: OracleMemoryConfig,\n",
    "        session_id: str,\n",
    "        llm: BaseLanguageModel,\n",
    "        agent_id: str = \"default_agent\",\n",
    "    ) -> ConversationSummaryMemory:\n",
    "        \"\"\"Create LangChain ConversationSummaryMemory with Oracle backend\"\"\"\n",
    "        memory = create_oracle_agent_memory(\n",
    "            oracle_config=oracle_config,\n",
    "            session_id=session_id,\n",
    "            agent_id=agent_id\n",
    "        )\n",
    "        \n",
    "        return ConversationSummaryMemory(\n",
    "            llm=llm,\n",
    "            chat_memory=memory.get_chat_message_history(),\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "print(\"✓ LangChain Agent Builders defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ca37e",
   "metadata": {},
   "source": [
    "## 8. Factory and Utility Functions\n",
    "\n",
    "Helper functions for creating and testing Oracle memory stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Factory and Utility Functions\n",
    "# ============================================================================\n",
    "\n",
    "def create_oracle_agent_memory(\n",
    "    oracle_config: OracleMemoryConfig,\n",
    "    session_id: str,\n",
    "    agent_id: str = \"default_agent\",\n",
    "    create_tables: bool = True\n",
    ") -> OracleAgentMemory:\n",
    "    \"\"\"Factory function to create Oracle memory store\"\"\"\n",
    "    engine = create_engine(oracle_config.get_connection_string())\n",
    "    \n",
    "    if create_tables:\n",
    "        Base.metadata.create_all(engine)\n",
    "    \n",
    "    return OracleAgentMemory(\n",
    "        engine=engine,\n",
    "        session_id=session_id,\n",
    "        agent_id=agent_id\n",
    "    )\n",
    "\n",
    "\n",
    "def test_oracle_connection(oracle_config: OracleMemoryConfig) -> bool:\n",
    "    \"\"\"Test Oracle database connection\"\"\"\n",
    "    try:\n",
    "        engine = create_engine(oracle_config.get_connection_string())\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(sa.text(\"SELECT 1 FROM DUAL\"))\n",
    "            return result.fetchone() is not None\n",
    "    except Exception as e:\n",
    "        print(f\"Connection test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"✓ Factory and utility functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04df6f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Complete Examples and Testing\n",
    "\n",
    "## Example 1: Mock Memory Store Setup\n",
    "\n",
    "Demonstrate the Oracle Agent Memory implementation using mock data to avoid requiring an actual Oracle database connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Mock Memory Store for Testing (without Oracle Database)\n",
    "# ============================================================================\n",
    "\n",
    "class MockOracleAgentMemory:\n",
    "    \"\"\"Mock implementation for testing without actual Oracle database\"\"\"\n",
    "    \n",
    "    def __init__(self, session_id: str, agent_id: str = \"default_agent\"):\n",
    "        self.session_id = session_id\n",
    "        self.agent_id = agent_id\n",
    "        self.conversations = []\n",
    "        self.entities = []\n",
    "        self.tasks = []\n",
    "        self.embeddings = []\n",
    "        self.task_counter = 1\n",
    "    \n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"Save conversation context\"\"\"\n",
    "        if \"input\" in inputs:\n",
    "            self.conversations.append({\n",
    "                \"type\": \"human\",\n",
    "                \"content\": inputs[\"input\"],\n",
    "                \"created_at\": datetime.utcnow().isoformat()\n",
    "            })\n",
    "        \n",
    "        if \"output\" in outputs:\n",
    "            self.conversations.append({\n",
    "                \"type\": \"ai\",\n",
    "                \"content\": outputs[\"output\"],\n",
    "                \"created_at\": datetime.utcnow().isoformat()\n",
    "            })\n",
    "    \n",
    "    def add_entity(self, entity_type: str, entity_name: str, entity_value: Dict) -> None:\n",
    "        \"\"\"Add entity to memory\"\"\"\n",
    "        self.entities.append({\n",
    "            \"type\": entity_type,\n",
    "            \"name\": entity_name,\n",
    "            \"value\": entity_value,\n",
    "            \"mention_count\": 1,\n",
    "            \"last_mentioned\": datetime.utcnow().isoformat()\n",
    "        })\n",
    "    \n",
    "    def get_entities(self, entity_type: Optional[str] = None) -> List[Dict]:\n",
    "        \"\"\"Get entities from memory\"\"\"\n",
    "        if entity_type:\n",
    "            return [e for e in self.entities if e[\"type\"] == entity_type]\n",
    "        return self.entities\n",
    "    \n",
    "    def add_task(self, task_description: str, result: Optional[Dict] = None) -> int:\n",
    "        \"\"\"Add task to memory\"\"\"\n",
    "        task_id = self.task_counter\n",
    "        self.task_counter += 1\n",
    "        self.tasks.append({\n",
    "            \"id\": task_id,\n",
    "            \"description\": task_description,\n",
    "            \"status\": \"in_progress\",\n",
    "            \"result\": result,\n",
    "            \"created_at\": datetime.utcnow().isoformat()\n",
    "        })\n",
    "        return task_id\n",
    "    \n",
    "    def update_task_status(self, task_id: int, status: str, result: Optional[Dict] = None) -> None:\n",
    "        \"\"\"Update task status\"\"\"\n",
    "        for task in self.tasks:\n",
    "            if task[\"id\"] == task_id:\n",
    "                task[\"status\"] = status\n",
    "                if result:\n",
    "                    task[\"result\"] = result\n",
    "                if status == \"completed\":\n",
    "                    task[\"completed_at\"] = datetime.utcnow().isoformat()\n",
    "                break\n",
    "    \n",
    "    def get_conversation_history(self, limit: Optional[int] = None) -> List[Dict]:\n",
    "        \"\"\"Get conversation history\"\"\"\n",
    "        history = self.conversations\n",
    "        if limit:\n",
    "            return history[-limit:]\n",
    "        return history\n",
    "    \n",
    "    def add_embedding(self, content: str, embedding: List[float], metadata: Optional[Dict] = None) -> None:\n",
    "        \"\"\"Add embedding to memory\"\"\"\n",
    "        self.embeddings.append({\n",
    "            \"content\": content,\n",
    "            \"embedding\": embedding,\n",
    "            \"metadata\": metadata or {},\n",
    "            \"created_at\": datetime.utcnow().isoformat()\n",
    "        })\n",
    "    \n",
    "    def get_embeddings(self, limit: Optional[int] = None) -> List[Dict]:\n",
    "        \"\"\"Get embeddings from memory\"\"\"\n",
    "        if limit:\n",
    "            return self.embeddings[-limit:]\n",
    "        return self.embeddings\n",
    "\n",
    "\n",
    "# Create mock memory instance for demonstrations\n",
    "print(\"✓ Mock Memory Store created for testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b621c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 2: Test Memory Storage Operations\n",
    "\n",
    "Test all memory storage methods with the mock memory store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mock memory\n",
    "mock_memory = MockOracleAgentMemory(\n",
    "    session_id=\"chat_session_001\",\n",
    "    agent_id=\"financial_advisor\"\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTING MEMORY STORAGE OPERATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test 1: Save conversation context\n",
    "print(\"\\n1. Saving Conversation Context...\")\n",
    "mock_memory.save_context(\n",
    "    inputs={\"input\": \"What is the current market trend?\"},\n",
    "    outputs={\"output\": \"Based on recent data, the market shows a bullish trend with tech stocks leading the gains.\"}\n",
    ")\n",
    "mock_memory.save_context(\n",
    "    inputs={\"input\": \"Which sectors are performing best?\"},\n",
    "    outputs={\"output\": \"Technology, Healthcare, and Energy sectors are showing strong performance this quarter.\"}\n",
    ")\n",
    "print(\"✓ Conversation context saved\")\n",
    "\n",
    "# Test 2: Add entities\n",
    "print(\"\\n2. Adding Entities...\")\n",
    "mock_memory.add_entity(\n",
    "    entity_type=\"person\",\n",
    "    entity_name=\"John Smith\",\n",
    "    entity_value={\"role\": \"financial_analyst\", \"expertise\": [\"stocks\", \"bonds\"]}\n",
    ")\n",
    "mock_memory.add_entity(\n",
    "    entity_type=\"organization\",\n",
    "    entity_name=\"TechCorp\",\n",
    "    entity_value={\"sector\": \"Technology\", \"market_cap\": \"500B\", \"recent_performance\": \"bullish\"}\n",
    ")\n",
    "print(\"✓ Entities added successfully\")\n",
    "\n",
    "# Test 3: Add tasks\n",
    "print(\"\\n3. Adding Tasks...\")\n",
    "task_id1 = mock_memory.add_task(\n",
    "    task_description=\"Analyze quarterly earnings report\",\n",
    "    result={\"status\": \"started\"}\n",
    ")\n",
    "print(f\"✓ Task {task_id1} created: Analyze quarterly earnings\")\n",
    "\n",
    "task_id2 = mock_memory.add_task(\n",
    "    task_description=\"Generate portfolio recommendations\"\n",
    ")\n",
    "print(f\"✓ Task {task_id2} created: Generate recommendations\")\n",
    "\n",
    "# Test 4: Update task status\n",
    "print(\"\\n4. Updating Task Status...\")\n",
    "mock_memory.update_task_status(\n",
    "    task_id=task_id1,\n",
    "    status=\"completed\",\n",
    "    result={\"analysis\": \"Strong performance across all metrics\", \"recommendation\": \"Hold\"}\n",
    ")\n",
    "print(f\"✓ Task {task_id1} completed with results\")\n",
    "\n",
    "# Test 5: Add embeddings\n",
    "print(\"\\n5. Adding Embeddings...\")\n",
    "sample_embeddings = [\n",
    "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    [0.15, 0.25, 0.35, 0.45, 0.55],\n",
    "    [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "]\n",
    "sample_texts = [\n",
    "    \"Oracle database is powerful for enterprise applications\",\n",
    "    \"Vector search enables semantic similarity matching\",\n",
    "    \"LangChain provides excellent LLM integration\"\n",
    "]\n",
    "\n",
    "for text, embedding in zip(sample_texts, sample_embeddings):\n",
    "    mock_memory.add_embedding(\n",
    "        content=text,\n",
    "        embedding=embedding,\n",
    "        metadata={\"source\": \"documentation\", \"type\": \"system_message\"}\n",
    "    )\n",
    "print(\"✓ Embeddings added successfully\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ All storage operations completed successfully!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae62ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 3: Test Memory Retrieval Operations\n",
    "\n",
    "Test all memory retrieval methods to extract stored information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TESTING MEMORY RETRIEVAL OPERATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Retrieve conversation history\n",
    "print(\"\\n1. Conversation History:\")\n",
    "print(\"-\" * 70)\n",
    "history = mock_memory.get_conversation_history()\n",
    "for i, msg in enumerate(history, 1):\n",
    "    msg_type = msg[\"type\"].upper()\n",
    "    content = msg[\"content\"][:80] + \"...\" if len(msg[\"content\"]) > 80 else msg[\"content\"]\n",
    "    print(f\"{i}. [{msg_type}] {content}\")\n",
    "print(f\"\\nTotal messages: {len(history)}\")\n",
    "\n",
    "# Retrieve entities\n",
    "print(\"\\n2. Stored Entities:\")\n",
    "print(\"-\" * 70)\n",
    "entities = mock_memory.get_entities()\n",
    "for entity in entities:\n",
    "    print(f\"  • {entity['type'].upper()}: {entity['name']}\")\n",
    "    print(f\"    Value: {entity['value']}\")\n",
    "print(f\"\\nTotal entities: {len(entities)}\")\n",
    "\n",
    "# Retrieve tasks\n",
    "print(\"\\n3. Task History:\")\n",
    "print(\"-\" * 70)\n",
    "for task in mock_memory.tasks:\n",
    "    print(f\"  Task {task['id']}: {task['description']}\")\n",
    "    print(f\"    Status: {task['status']}\")\n",
    "    if task['result']:\n",
    "        print(f\"    Result: {task['result']}\")\n",
    "print(f\"\\nTotal tasks: {len(mock_memory.tasks)}\")\n",
    "\n",
    "# Retrieve embeddings\n",
    "print(\"\\n4. Stored Embeddings:\")\n",
    "print(\"-\" * 70)\n",
    "embeddings = mock_memory.get_embeddings()\n",
    "for i, emb in enumerate(embeddings, 1):\n",
    "    print(f\"{i}. Content: {emb['content'][:60]}...\")\n",
    "    print(f\"   Vector dimension: {len(emb['embedding'])}\")\n",
    "    print(f\"   Metadata: {emb['metadata']}\")\n",
    "print(f\"\\nTotal embeddings: {len(embeddings)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✓ All retrieval operations completed successfully!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c39dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example 4: Visualize Memory State\n",
    "\n",
    "Create visualizations to understand the memory state and operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc551c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Oracle Agent Memory Statistics', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Conversation Distribution\n",
    "ax1 = axes[0, 0]\n",
    "message_types = [msg[\"type\"] for msg in mock_memory.get_conversation_history()]\n",
    "human_count = message_types.count(\"human\")\n",
    "ai_count = message_types.count(\"ai\")\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "ax1.bar(['Human Messages', 'AI Messages'], [human_count, ai_count], color=colors)\n",
    "ax1.set_title('Conversation Distribution', fontweight='bold')\n",
    "ax1.set_ylabel('Count')\n",
    "for i, v in enumerate([human_count, ai_count]):\n",
    "    ax1.text(i, v + 0.1, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 2: Task Status Distribution\n",
    "ax2 = axes[0, 1]\n",
    "task_statuses = [task[\"status\"] for task in mock_memory.tasks]\n",
    "status_counts = {}\n",
    "for status in task_statuses:\n",
    "    status_counts[status] = status_counts.get(status, 0) + 1\n",
    "statuses = list(status_counts.keys())\n",
    "counts = list(status_counts.values())\n",
    "colors_tasks = ['#95E1D3', '#F38181']\n",
    "ax2.pie(counts, labels=statuses, autopct='%1.1f%%', colors=colors_tasks, startangle=90)\n",
    "ax2.set_title('Task Status Distribution', fontweight='bold')\n",
    "\n",
    "# Plot 3: Entity Types\n",
    "ax3 = axes[1, 0]\n",
    "entity_types = [entity[\"type\"] for entity in mock_memory.get_entities()]\n",
    "entity_type_counts = {}\n",
    "for etype in entity_types:\n",
    "    entity_type_counts[etype] = entity_type_counts.get(etype, 0) + 1\n",
    "types = list(entity_type_counts.keys())\n",
    "type_counts = list(entity_type_counts.values())\n",
    "colors_entities = ['#AA96DA', '#FCBAD3']\n",
    "ax3.barh(types, type_counts, color=colors_entities)\n",
    "ax3.set_title('Entity Types', fontweight='bold')\n",
    "ax3.set_xlabel('Count')\n",
    "for i, v in enumerate(type_counts):\n",
    "    ax3.text(v + 0.1, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "# Plot 4: Memory Content Summary\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "MEMORY STATE SUMMARY\n",
    "\n",
    "Session ID: {mock_memory.session_id}\n",
    "Agent ID: {mock_memory.agent_id}\n",
    "\n",
    "Conversations: {len(mock_memory.conversations)}\n",
    "Entities: {len(mock_memory.entities)}\n",
    "Tasks: {len(mock_memory.tasks)}\n",
    "Embeddings: {len(mock_memory.embeddings)}\n",
    "\n",
    "Task Completion:\n",
    "  • Completed: {len([t for t in mock_memory.tasks if t['status'] == 'completed'])}\n",
    "  • Pending: {len([t for t in mock_memory.tasks if t['status'] != 'completed'])}\n",
    "\"\"\"\n",
    "ax4.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Memory state visualizations displayed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16edc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementation Guide: Using with Real Oracle Database\n",
    "\n",
    "### Step 1: Configure Oracle Connection\n",
    "\n",
    "To connect to a real Oracle database, update your configuration:\n",
    "\n",
    "```python\n",
    "# For Oracle Cloud (recommended)\n",
    "oracle_config = OracleMemoryConfig(\n",
    "    username=\"your_username\",\n",
    "    password=\"your_password\",\n",
    "    host=\"your_oracle_host\",\n",
    "    port=1521,\n",
    "    service_name=\"your_service_name\"\n",
    ")\n",
    "\n",
    "# OR for traditional Oracle setup\n",
    "oracle_config = OracleMemoryConfig(\n",
    "    username=\"your_username\",\n",
    "    password=\"your_password\",\n",
    "    host=\"localhost\",\n",
    "    port=1521,\n",
    "    sid=\"orcl\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Step 2: Create Memory Instance\n",
    "\n",
    "```python\n",
    "# Create and initialize the memory store\n",
    "memory = create_oracle_agent_memory(\n",
    "    oracle_config=oracle_config,\n",
    "    session_id=\"my_session_001\",\n",
    "    agent_id=\"my_agent\",\n",
    "    create_tables=True  # Creates tables if they don't exist\n",
    ")\n",
    "```\n",
    "\n",
    "### Step 3: Use with LangChain Agents\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0.7, api_key=\"your_openai_key\")\n",
    "\n",
    "# Create conversation chain with Oracle memory\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=OracleLangChainMemoryBuilder.create_conversation_memory(\n",
    "        oracle_config=oracle_config,\n",
    "        session_id=\"conversation_001\",\n",
    "        agent_id=\"chat_bot\"\n",
    "    ),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Use the conversation\n",
    "response = conversation.run(\"How are you today?\")\n",
    "```\n",
    "\n",
    "### Step 4: Advanced Memory Operations\n",
    "\n",
    "```python\n",
    "# Add entities for context\n",
    "memory.add_entity(\n",
    "    entity_type=\"person\",\n",
    "    entity_name=\"John Doe\",\n",
    "    entity_value={\"role\": \"analyst\", \"department\": \"finance\"}\n",
    ")\n",
    "\n",
    "# Add tasks and track progress\n",
    "task_id = memory.add_task(\"Generate quarterly report\")\n",
    "# ... do work ...\n",
    "memory.update_task_status(task_id, \"completed\", result={\"report\": \"Q1_2024\"})\n",
    "\n",
    "# Add embeddings for semantic search\n",
    "memory.add_embedding(\n",
    "    content=\"Important business document\",\n",
    "    embedding=[0.1, 0.2, 0.3, ...],\n",
    "    metadata={\"type\": \"document\", \"source\": \"external\"}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6518b1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Features\n",
    "\n",
    "### Core Features Implemented\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Conversation Memory** | Persistent storage of chat history using Oracle database |\n",
    "| **Entity Tracking** | Extract and track entities mentioned in conversations |\n",
    "| **Task Management** | Record and monitor agent task execution |\n",
    "| **Vector Embeddings** | Store embeddings for semantic search capabilities |\n",
    "| **LangChain Integration** | Full compatibility with LangChain memory and chains |\n",
    "| **Connection Pooling** | Efficient database connection management |\n",
    "| **Metadata Support** | Flexible JSON metadata storage for extensibility |\n",
    "\n",
    "### Database Schema\n",
    "\n",
    "The implementation uses four main tables:\n",
    "\n",
    "1. **agent_conversation_memory** - Stores all conversation messages\n",
    "2. **agent_entity_memory** - Tracks extracted entities and facts\n",
    "3. **agent_tasks** - Records task execution history\n",
    "4. **agent_vector_embeddings** - Stores vector embeddings for semantic search\n",
    "\n",
    "### Key Classes\n",
    "\n",
    "- `OracleMemoryConfig` - Configuration management\n",
    "- `OracleAgentMemory` - Main memory store implementation\n",
    "- `OracleSQLChatMessageHistory` - LangChain chat history integration\n",
    "- `OracleSQLAgentBuilder` - SQL agent builder utilities\n",
    "- `MockOracleAgentMemory` - Testing without needing Oracle\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To use this in production:\n",
    "\n",
    "1. Set up an Oracle database instance (Oracle Cloud, on-premise, or Docker)\n",
    "2. Install required packages: `sqlalchemy`, `oracledb`, `langchain`\n",
    "3. Configure your Oracle credentials\n",
    "4. Initialize the memory store with your configuration\n",
    "5. Integrate with your LangChain agents and chains\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Oracle Database Documentation](https://docs.oracle.com/en/database/)\n",
    "- [LangChain Memory Documentation](https://python.langchain.com/docs/modules/memory/)\n",
    "- [SQLAlchemy + Oracle Setup](https://docs.sqlalchemy.org/en/20/dialects/oracle/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
