{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83b9653b",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhusudhanrao-ppm/dbdevrel/blob/main/multicloud-oracledb-at-azure/oracle-azure-similarity-search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478247c9",
      "metadata": {
        "id": "478247c9"
      },
      "source": [
        "# Oracle Database Similarity Search on Azure\n",
        "\n",
        "This notebook demonstrates how to connect to an Oracle Autonomous Database hosted on Microsoft Azure and perform semantic similarity searches on text or numerical data using vector embeddings and similarity metrics.\n",
        "\n",
        "## Overview\n",
        "\n",
        "- **Cloud Platform**: Microsoft Azure\n",
        "- **Database**: Oracle Autonomous Database@Azure\n",
        "- **Embedding Model**: sentence-transformers for semantic embeddings\n",
        "- **Similarity Metric**: Cosine similarity and Euclidean distance\n",
        "- **Use Cases**: Document retrieval, product recommendations, semantic search, vector similarity\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Azure subscription with Oracle Database@Azure access\n",
        "- Oracle Autonomous Database instance running on Azure\n",
        "- Database connection details (endpoint, credentials)\n",
        "- Google Colab environment (or local Jupyter Notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa26d733",
      "metadata": {
        "id": "fa26d733"
      },
      "source": [
        "## Section 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b5bf7e",
      "metadata": {
        "id": "67b5bf7e"
      },
      "outputs": [],
      "source": [
        "# Install required packages for Google Colab\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    'cx_Oracle>=8.0',\n",
        "    'azure-identity',\n",
        "    'azure-keyvault-secrets',\n",
        "    'pandas',\n",
        "    'numpy',\n",
        "    'scikit-learn',\n",
        "    'sentence-transformers',\n",
        "    'matplotlib',\n",
        "    'seaborn'\n",
        "]\n",
        "\n",
        "print(\"Installing required packages...\")\n",
        "for package in packages:\n",
        "    print(f\"  Installing {package}...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "print(\"\\nâœ“ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "586160e0",
      "metadata": {
        "id": "586160e0"
      },
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import cx_Oracle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "from sklearn.preprocessing import normalize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings\n",
        "import json\n",
        "from typing import Tuple, List, Optional\n",
        "\n",
        "# Azure libraries\n",
        "try:\n",
        "    from azure.identity import DefaultAzureCredential, ClientSecretCredential\n",
        "    from azure.keyvault.secrets import SecretClient\n",
        "    AZURE_AVAILABLE = True\n",
        "except ImportError:\n",
        "    AZURE_AVAILABLE = False\n",
        "    print(\"âš  Azure libraries available but optional for local testing\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ“ Core libraries imported successfully!\")\n",
        "if AZURE_AVAILABLE:\n",
        "    print(\"âœ“ Azure integration libraries loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b774e1a9",
      "metadata": {
        "id": "b774e1a9"
      },
      "source": [
        "## Interactive Search Function\n",
        "\n",
        "Use this cell to perform custom similarity searches on your data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942fb55d",
      "metadata": {
        "id": "942fb55d"
      },
      "outputs": [],
      "source": [
        "# Comprehensive Results Visualization and Analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "if search_engine is not None and len(all_results) > 0:\n",
        "    # Configure plotting style\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "    # Create subplots for each query\n",
        "    fig, axes = plt.subplots(1, len(all_results), figsize=(15, 5))\n",
        "    if len(all_results) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for idx, result_set in enumerate(all_results):\n",
        "        query = result_set['query']\n",
        "        results = result_set['results']\n",
        "\n",
        "        # Create bar chart for similarity scores\n",
        "        colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(results)))\n",
        "        bars = axes[idx].barh(range(len(results)), results['similarity_score'], color=colors)\n",
        "\n",
        "        axes[idx].set_yticks(range(len(results)))\n",
        "        axes[idx].set_yticklabels([f\"Rank {i+1}\" for i in range(len(results))], fontsize=9)\n",
        "        axes[idx].set_xlabel('Similarity Score', fontsize=10)\n",
        "        axes[idx].set_title(f'Query {idx+1}: \"{query[:40]}...\"', fontsize=11, fontweight='bold')\n",
        "        axes[idx].set_xlim(0, 1)\n",
        "\n",
        "        # Add value labels\n",
        "        for i, (bar, score) in enumerate(zip(bars, results['similarity_score'])):\n",
        "            axes[idx].text(score + 0.02, i, f'{score:.3f}', va='center', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"âœ“ Visualization displayed above\\n\")\n",
        "\n",
        "    # Summary statistics\n",
        "    print(\"=\"*80)\n",
        "    print(\"SEARCH ANALYTICS SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Total documents indexed: {len(df)}\")\n",
        "    print(f\"Embedding dimension: {df['embeddings'].iloc[0].shape[0]}\")\n",
        "    print(f\"Total queries executed: {len(all_results)}\")\n",
        "\n",
        "    # Aggregate statistics\n",
        "    all_scores = []\n",
        "    for result_set in all_results:\n",
        "        all_scores.extend(result_set['results']['similarity_score'].values)\n",
        "\n",
        "    if all_scores:\n",
        "        print(f\"\\nSimilarity Score Statistics:\")\n",
        "        print(f\"  Minimum: {min(all_scores):.4f}\")\n",
        "        print(f\"  Maximum: {max(all_scores):.4f}\")\n",
        "        print(f\"  Mean: {np.mean(all_scores):.4f}\")\n",
        "        print(f\"  Median: {np.median(all_scores):.4f}\")\n",
        "        print(f\"  Std Dev: {np.std(all_scores):.4f}\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "else:\n",
        "    print(\"âš  No results available for visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16a145c3",
      "metadata": {
        "id": "16a145c3"
      },
      "source": [
        "## Section 2: Configure Azure Credentials and Database Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78714e45",
      "metadata": {
        "id": "78714e45"
      },
      "outputs": [],
      "source": [
        "# Configure Azure Credentials and Database Connection\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Method 1: Retrieve credentials from Google Colab Secrets\n",
        "try:\n",
        "    ORACLE_HOST = userdata.get('ORACLE_AZURE_HOST')\n",
        "    ORACLE_USER = userdata.get('ORACLE_AZURE_USER')\n",
        "    ORACLE_PASSWORD = userdata.get('ORACLE_AZURE_PASSWORD')\n",
        "    ORACLE_SERVICE = userdata.get('ORACLE_AZURE_SERVICE')\n",
        "    print(\"âœ“ Database credentials loaded from Colab Secrets\")\n",
        "except:\n",
        "    # Method 2: Use environment variables or hardcoded values for testing\n",
        "    ORACLE_HOST = os.getenv('ORACLE_AZURE_HOST', 'your-oracle-db.oraclecloud.com')\n",
        "    ORACLE_USER = os.getenv('ORACLE_AZURE_USER', 'admin')\n",
        "    ORACLE_PASSWORD = os.getenv('ORACLE_AZURE_PASSWORD', 'your_password_here')\n",
        "    ORACLE_SERVICE = os.getenv('ORACLE_AZURE_SERVICE', 'ORCL')\n",
        "    print(\"âš  Using default/environment variables for credentials\")\n",
        "\n",
        "# Oracle Database Configuration\n",
        "DB_CONFIG = {\n",
        "    'host': ORACLE_HOST,\n",
        "    'port': 1521,\n",
        "    'service_name': ORACLE_SERVICE,\n",
        "    'user': ORACLE_USER,\n",
        "    'password': ORACLE_PASSWORD,\n",
        "    'wallet_location': None  # Optional: path to wallet for mTLS\n",
        "}\n",
        "\n",
        "# Optional: Azure Key Vault Integration (for secure credential storage)\n",
        "def get_credentials_from_azure_keyvault(vault_url: str, secret_names: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Retrieve database credentials from Azure Key Vault\n",
        "\n",
        "    Args:\n",
        "        vault_url: Azure Key Vault URL\n",
        "        secret_names: Dict mapping config keys to secret names\n",
        "\n",
        "    Returns:\n",
        "        Updated configuration dictionary\n",
        "    \"\"\"\n",
        "    if not AZURE_AVAILABLE:\n",
        "        print(\"âš  Azure libraries not available\")\n",
        "        return {}\n",
        "\n",
        "    try:\n",
        "        credential = DefaultAzureCredential()\n",
        "        client = SecretClient(vault_url=vault_url, credential=credential)\n",
        "\n",
        "        credentials = {}\n",
        "        for key, secret_name in secret_names.items():\n",
        "            credentials[key] = client.get_secret(secret_name).value\n",
        "\n",
        "        print(\"âœ“ Credentials retrieved from Azure Key Vault\")\n",
        "        return credentials\n",
        "    except Exception as e:\n",
        "        print(f\"âš  Could not retrieve from Key Vault: {str(e)}\")\n",
        "        return {}\n",
        "\n",
        "# Display configuration (without exposing password)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ORACLE DATABASE CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Host: {DB_CONFIG['host']}\")\n",
        "print(f\"Port: {DB_CONFIG['port']}\")\n",
        "print(f\"Service Name: {DB_CONFIG['service_name']}\")\n",
        "print(f\"Username: {DB_CONFIG['user']}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a453532f",
      "metadata": {
        "id": "a453532f"
      },
      "source": [
        "## Section 3: Connect to Oracle Database on Azure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ce7e06",
      "metadata": {
        "id": "d6ce7e06"
      },
      "outputs": [],
      "source": [
        "# Establish Oracle Database Connection\n",
        "def create_oracle_connection(config: dict) -> Optional[cx_Oracle.Connection]:\n",
        "    \"\"\"\n",
        "    Create a connection to Oracle Autonomous Database on Azure\n",
        "\n",
        "    Args:\n",
        "        config (dict): Database configuration\n",
        "\n",
        "    Returns:\n",
        "        cx_Oracle.Connection or None: Database connection object\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Build connection string\n",
        "        if config.get('wallet_location'):\n",
        "            # Using wallet for mTLS (recommended for production)\n",
        "            dsn = cx_Oracle.makedsn(\n",
        "                config['host'],\n",
        "                config['port'],\n",
        "                service_name=config['service_name']\n",
        "            )\n",
        "            connection = cx_Oracle.connect(\n",
        "                user=config['user'],\n",
        "                password=config['password'],\n",
        "                dsn=dsn\n",
        "            )\n",
        "        else:\n",
        "            # Direct connection string\n",
        "            connection_string = (\n",
        "                f\"{config['user']}/{config['password']}@\"\n",
        "                f\"{config['host']}:{config['port']}/{config['service_name']}\"\n",
        "            )\n",
        "            connection = cx_Oracle.connect(connection_string)\n",
        "\n",
        "        print(\"âœ“ Successfully connected to Oracle Autonomous Database on Azure\")\n",
        "        print(f\"  Database Version: {connection.version}\")\n",
        "        return connection\n",
        "\n",
        "    except cx_Oracle.DatabaseError as e:\n",
        "        error, = e.args\n",
        "        print(f\"âœ— Database Connection Error: {error.message}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Connection Error: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting Tips:\")\n",
        "        print(\"  1. Verify database endpoint is correct\")\n",
        "        print(\"  2. Check network connectivity (firewall rules)\")\n",
        "        print(\"  3. Validate username and password\")\n",
        "        print(\"  4. Ensure Oracle Database@Azure is running\")\n",
        "        return None\n",
        "\n",
        "# Establish connection\n",
        "oracle_conn = create_oracle_connection(DB_CONFIG)\n",
        "\n",
        "if oracle_conn:\n",
        "    print(\"\\nâœ“ Connection Status: ACTIVE\")\n",
        "else:\n",
        "    print(\"\\nâœ— Connection Status: FAILED\")\n",
        "    print(\"Please update credentials and retry connection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c15f1651",
      "metadata": {
        "id": "c15f1651"
      },
      "source": [
        "## Section 4: Load Data from Oracle Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125c8f00",
      "metadata": {
        "id": "125c8f00"
      },
      "outputs": [],
      "source": [
        "# Load Data from Oracle Database\n",
        "def load_data_from_oracle(connection: cx_Oracle.Connection,\n",
        "                          table_name: str,\n",
        "                          columns: Optional[List[str]] = None,\n",
        "                          limit: Optional[int] = None) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Load data from an Oracle table into a pandas DataFrame\n",
        "\n",
        "    Args:\n",
        "        connection: cx_Oracle connection object\n",
        "        table_name: Name of the table to query\n",
        "        columns: List of column names (None = all)\n",
        "        limit: Maximum number of rows to retrieve\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Data loaded from the table\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if columns:\n",
        "            column_str = \", \".join(columns)\n",
        "            query = f\"SELECT {column_str} FROM {table_name}\"\n",
        "        else:\n",
        "            query = f\"SELECT * FROM {table_name}\"\n",
        "\n",
        "        if limit:\n",
        "            query = f\"SELECT * FROM ({query}) WHERE ROWNUM <= {limit}\"\n",
        "\n",
        "        # Read using pandas with Oracle connection\n",
        "        df = pd.read_sql(query, connection)\n",
        "\n",
        "        print(f\"âœ“ Successfully loaded {len(df)} records from {table_name}\")\n",
        "        print(f\"  Columns: {list(df.columns)}\")\n",
        "        print(f\"  Data shape: {df.shape}\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Error loading data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Load sample data\n",
        "if oracle_conn:\n",
        "    # Example: Load from a sample documents table\n",
        "    TABLE_NAME = 'DOCUMENTS'  # Replace with your actual table name\n",
        "    COLUMNS = ['ID', 'TITLE', 'CONTENT', 'CATEGORY']  # Adjust columns as needed\n",
        "    LIMIT = 100  # Limit to first 100 records for demo\n",
        "\n",
        "    print(\"Loading data from Oracle Database...\")\n",
        "    df = load_data_from_oracle(oracle_conn, TABLE_NAME, COLUMNS, LIMIT)\n",
        "\n",
        "    if df is not None and not df.empty:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"DATA PREVIEW\")\n",
        "        print(\"=\"*60)\n",
        "        print(df.head())\n",
        "        print(f\"\\nData Info:\")\n",
        "        print(f\"  Rows: {len(df)}\")\n",
        "        print(f\"  Columns: {df.shape[1]}\")\n",
        "        print(f\"  Memory Usage: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB\")\n",
        "    else:\n",
        "        print(\"âš  No data loaded or connection failed\")\n",
        "else:\n",
        "    print(\"Cannot load data: Database connection not established\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4273a15f",
      "metadata": {
        "id": "4273a15f"
      },
      "source": [
        "## Section 5: Prepare Data for Similarity Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0310a11",
      "metadata": {
        "id": "b0310a11"
      },
      "outputs": [],
      "source": [
        "# Load Embedding Model\n",
        "print(\"Loading semantic embedding model...\")\n",
        "print(\"(First run may take 1-2 minutes as model is downloaded)\")\n",
        "\n",
        "try:\n",
        "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    print(\"âœ“ Embedding model loaded successfully\")\n",
        "    print(f\"  Model: all-MiniLM-L6-v2\")\n",
        "    print(f\"  Embedding dimension: 384\")\n",
        "except Exception as e:\n",
        "    print(f\"âœ— Error loading model: {str(e)}\")\n",
        "    embedding_model = None\n",
        "\n",
        "# Function to generate embeddings\n",
        "def generate_embeddings(texts: List[str], batch_size: int = 32) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generate semantic embeddings for text data\n",
        "\n",
        "    Args:\n",
        "        texts: List of text strings\n",
        "        batch_size: Batch size for processing\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Embeddings array (n_samples, 384)\n",
        "    \"\"\"\n",
        "    print(f\"Generating embeddings for {len(texts)} documents...\")\n",
        "    embeddings = embedding_model.encode(texts, show_progress_bar=True, batch_size=batch_size)\n",
        "    print(f\"âœ“ Generated embeddings with shape: {embeddings.shape}\")\n",
        "    return embeddings\n",
        "\n",
        "# Prepare and embed data\n",
        "if df is not None and embedding_model is not None and not df.empty:\n",
        "    # Identify text column\n",
        "    if 'CONTENT' in df.columns:\n",
        "        text_column = 'CONTENT'\n",
        "    elif 'TITLE' in df.columns:\n",
        "        text_column = 'TITLE'\n",
        "    else:\n",
        "        # Use first text column found\n",
        "        text_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "        text_column = text_columns[0] if text_columns else None\n",
        "\n",
        "    if text_column:\n",
        "        # Clean text data\n",
        "        df['text_clean'] = (df[text_column].fillna('').astype(str).str.strip()\n",
        "                           .str.replace('\\n', ' ').str.replace('\\r', ' '))\n",
        "\n",
        "        # Remove empty documents\n",
        "        df = df[df['text_clean'].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "        print(f\"\\nPreparing text from column: '{text_column}'\")\n",
        "        print(f\"Documents with text: {len(df)}\")\n",
        "        print(f\"\\nSample text:\\n{df['text_clean'].iloc[0][:250]}...\\n\")\n",
        "\n",
        "        # Generate embeddings\n",
        "        embeddings = generate_embeddings(df['text_clean'].tolist())\n",
        "\n",
        "        # Store embeddings\n",
        "        df['embeddings'] = [embeddings[i] for i in range(len(df))]\n",
        "\n",
        "        print(f\"\\nâœ“ Data preparation complete\")\n",
        "        print(f\"  Total documents: {len(df)}\")\n",
        "        print(f\"  Embedding dimension: {embeddings.shape[1]}\")\n",
        "    else:\n",
        "        print(\"âš  No text column found for embedding\")\n",
        "        df = None\n",
        "else:\n",
        "    print(\"âš  Cannot prepare data: missing connection, model, or dataframe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a89f5c7",
      "metadata": {
        "id": "4a89f5c7"
      },
      "source": [
        "## Section 6: Implement Similarity Search Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d9327cf",
      "metadata": {
        "id": "0d9327cf"
      },
      "outputs": [],
      "source": [
        "# Interactive similarity search function\n",
        "def perform_custom_search(search_engine, query_text: str, top_k: int = 5, method: str = 'cosine'):\n",
        "    \"\"\"\n",
        "    Perform custom similarity search with detailed results display\n",
        "\n",
        "    Args:\n",
        "        search_engine: OracleSimilaritySearch instance\n",
        "        query_text: Query string\n",
        "        top_k: Number of results to return\n",
        "        method: 'cosine' or 'euclidean'\n",
        "    \"\"\"\n",
        "    if search_engine is None:\n",
        "        print(\"âš  Search engine not available\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nðŸ” SIMILARITY SEARCH\")\n",
        "    print(f\"Query: '{query_text}'\")\n",
        "    print(f\"Method: {method.upper()}\")\n",
        "    print(f\"Top Results: {top_k}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # Execute search\n",
        "    if method == 'cosine':\n",
        "        results = search_engine.cosine_similarity_search(query_text, top_k=top_k)\n",
        "        score_col = 'similarity_score'\n",
        "    else:\n",
        "        results = search_engine.euclidean_distance_search(query_text, top_k=top_k)\n",
        "        score_col = 'distance'\n",
        "\n",
        "    # Display results\n",
        "    for idx, row in results.iterrows():\n",
        "        print(f\"\\nâœ“ Rank {row['rank']}: {row[score_col]:.4f}\")\n",
        "\n",
        "        # Show available metadata\n",
        "        for col in results.columns:\n",
        "            if col not in ['rank', 'similarity_score', 'distance', 'search_method']:\n",
        "                value = row[col]\n",
        "                if value is not None:\n",
        "                    if isinstance(value, str) and len(str(value)) > 100:\n",
        "                        print(f\"  {col}: {str(value)[:100]}...\")\n",
        "                    else:\n",
        "                        print(f\"  {col}: {value}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    return results\n",
        "\n",
        "# Example: Custom search\n",
        "if search_engine is not None:\n",
        "    # Modify this query to test\n",
        "    custom_query = \"Oracle database performance optimization on Azure\"\n",
        "    custom_results = perform_custom_search(\n",
        "        search_engine,\n",
        "        custom_query,\n",
        "        top_k=5,\n",
        "        method='cosine'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbd2ade",
      "metadata": {
        "id": "dfbd2ade"
      },
      "source": [
        "## Section 7: Execute Similarity Search Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a91fe47",
      "metadata": {
        "id": "7a91fe47"
      },
      "outputs": [],
      "source": [
        "# Similarity Search Engine\n",
        "class OracleSimilaritySearch:\n",
        "    \"\"\"\n",
        "    Semantic similarity search engine for Oracle Autonomous Database documents\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame, embedding_model):\n",
        "        \"\"\"\n",
        "        Initialize similarity search engine\n",
        "\n",
        "        Args:\n",
        "            dataframe: DataFrame with embeddings column\n",
        "            embedding_model: Pre-trained embedding model\n",
        "        \"\"\"\n",
        "        self.df = dataframe.copy()\n",
        "        self.model = embedding_model\n",
        "        self.embeddings = np.array([emb for emb in dataframe['embeddings'].values])\n",
        "        print(f\"âœ“ Search engine initialized with {len(self.df)} documents\")\n",
        "\n",
        "    def cosine_similarity_search(self, query: str, top_k: int = 5) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Find most similar documents using cosine similarity\n",
        "\n",
        "        Args:\n",
        "            query: Query text\n",
        "            top_k: Number of results to return\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Top K results with similarity scores\n",
        "        \"\"\"\n",
        "        # Generate query embedding\n",
        "        query_embedding = self.model.encode([query])[0].reshape(1, -1)\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
        "\n",
        "        # Get top K results\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "\n",
        "        # Build results dataframe\n",
        "        results = self.df.iloc[top_indices].copy()\n",
        "        results['similarity_score'] = similarities[top_indices]\n",
        "        results['rank'] = range(1, len(results) + 1)\n",
        "        results['search_method'] = 'cosine_similarity'\n",
        "\n",
        "        # Clean up columns for display\n",
        "        cols_to_drop = [col for col in results.columns if col in ['embeddings', 'text_clean']]\n",
        "        if cols_to_drop:\n",
        "            results = results.drop(columns=cols_to_drop)\n",
        "\n",
        "        return results.reset_index(drop=True)\n",
        "\n",
        "    def euclidean_distance_search(self, query: str, top_k: int = 5) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Find most similar documents using Euclidean distance\n",
        "\n",
        "        Args:\n",
        "            query: Query text\n",
        "            top_k: Number of results to return\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Top K results with distance scores\n",
        "        \"\"\"\n",
        "        # Generate query embedding\n",
        "        query_embedding = self.model.encode([query])[0].reshape(1, -1)\n",
        "\n",
        "        # Calculate Euclidean distance\n",
        "        distances = euclidean_distances(query_embedding, self.embeddings)[0]\n",
        "\n",
        "        # Get top K results (smallest distances)\n",
        "        top_indices = np.argsort(distances)[:top_k]\n",
        "\n",
        "        # Build results dataframe\n",
        "        results = self.df.iloc[top_indices].copy()\n",
        "        results['distance'] = distances[top_indices]\n",
        "        results['rank'] = range(1, len(results) + 1)\n",
        "        results['search_method'] = 'euclidean_distance'\n",
        "\n",
        "        # Clean up columns\n",
        "        cols_to_drop = [col for col in results.columns if col in ['embeddings', 'text_clean']]\n",
        "        if cols_to_drop:\n",
        "            results = results.drop(columns=cols_to_drop)\n",
        "\n",
        "        return results.reset_index(drop=True)\n",
        "\n",
        "    def hybrid_search(self, query: str, top_k: int = 5, method: str = 'cosine') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Perform hybrid search combining multiple similarity metrics\n",
        "\n",
        "        Args:\n",
        "            query: Query text\n",
        "            top_k: Number of results to return\n",
        "            method: 'cosine' or 'euclidean'\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Top K hybrid search results\n",
        "        \"\"\"\n",
        "        if method == 'cosine':\n",
        "            return self.cosine_similarity_search(query, top_k)\n",
        "        else:\n",
        "            return self.euclidean_distance_search(query, top_k)\n",
        "\n",
        "# Initialize search engine\n",
        "if df is not None and 'embeddings' in df.columns and embedding_model is not None:\n",
        "    search_engine = OracleSimilaritySearch(df, embedding_model)\n",
        "else:\n",
        "    search_engine = None\n",
        "    print(\"âš  Cannot initialize search engine\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaa291e",
      "metadata": {
        "id": "adaa291e"
      },
      "source": [
        "## Section 8: Display and Analyze Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee8ce31",
      "metadata": {
        "id": "2ee8ce31"
      },
      "outputs": [],
      "source": [
        "# Execute Similarity Search Queries\n",
        "if search_engine is not None:\n",
        "    # Define example queries\n",
        "    example_queries = [\n",
        "        \"artificial intelligence and machine learning\",\n",
        "        \"cloud database solutions and Azure services\",\n",
        "        \"data analytics and business intelligence\"\n",
        "    ]\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"EXECUTING SIMILARITY SEARCH QUERIES\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for idx, query in enumerate(example_queries, 1):\n",
        "        print(f\"\\nðŸ“‹ Query {idx}: '{query}'\")\n",
        "        print(\"-\"*80)\n",
        "\n",
        "        # Perform cosine similarity search\n",
        "        results = search_engine.cosine_similarity_search(query, top_k=3)\n",
        "        all_results.append({\n",
        "            'query': query,\n",
        "            'results': results\n",
        "        })\n",
        "\n",
        "        # Display results\n",
        "        for result_idx, row in results.iterrows():\n",
        "            print(f\"\\n  Rank {row['rank']}: Score = {row['similarity_score']:.4f}\")\n",
        "\n",
        "            # Display relevant columns\n",
        "            for col in results.columns:\n",
        "                if col not in ['rank', 'similarity_score', 'search_method']:\n",
        "                    value = row[col]\n",
        "                    if isinstance(value, str) and len(value) > 80:\n",
        "                        print(f\"  {col}: {value[:80]}...\")\n",
        "                    else:\n",
        "                        print(f\"  {col}: {value}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "else:\n",
        "    print(\"âš  Search engine not initialized. Cannot execute queries.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3844c181",
      "metadata": {
        "id": "3844c181"
      },
      "source": [
        "## Cleanup and Best Practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237c7d8f",
      "metadata": {
        "id": "237c7d8f"
      },
      "outputs": [],
      "source": [
        "# Close database connection\n",
        "if oracle_conn:\n",
        "    try:\n",
        "        oracle_conn.close()\n",
        "        print(\"âœ“ Oracle database connection closed\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš  Warning closing connection: {str(e)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BEST PRACTICES FOR PRODUCTION IMPLEMENTATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "best_practices = \"\"\"\n",
        "## Security Best Practices\n",
        "âœ“ Use Azure Key Vault for credential management\n",
        "âœ“ Enable mTLS (mutual TLS) with wallet files\n",
        "âœ“ Implement firewall rules and network security groups\n",
        "âœ“ Use managed identities instead of service principals\n",
        "âœ“ Enable SQL audit logging and monitoring\n",
        "âœ“ Apply row-level security (RLS) in Oracle\n",
        "\n",
        "## Performance Optimization\n",
        "âœ“ Cache embeddings in database (e.g., VECTOR datatype in Oracle 23c+)\n",
        "âœ“ Use connection pooling (cx_Oracle.SessionPool)\n",
        "âœ“ Batch process queries for large datasets\n",
        "âœ“ Implement approximate nearest neighbor (ANN) search\n",
        "âœ“ Create indexes on vector columns\n",
        "âœ“ Monitor query execution time and optimize queries\n",
        "\n",
        "## Scalability Considerations\n",
        "âœ“ Use dedicated vector databases for large-scale applications:\n",
        "  - Azure Cognitive Search\n",
        "  - Pinecone\n",
        "  - Milvus\n",
        "  - Weaviate\n",
        "âœ“ Implement pagination for large result sets\n",
        "âœ“ Use async queries for non-blocking operations\n",
        "âœ“ Implement rate limiting and caching layers\n",
        "\n",
        "## Data Management\n",
        "âœ“ Regularly update embeddings for new/modified documents\n",
        "âœ“ Version embedding models (track which model created each embedding)\n",
        "âœ“ Archive old embeddings periodically\n",
        "âœ“ Maintain consistency between database and embedding cache\n",
        "âœ“ Implement data validation and quality checks\n",
        "\n",
        "## Monitoring & Logging\n",
        "âœ“ Track query latency and response times\n",
        "âœ“ Monitor database connection health\n",
        "âœ“ Log embedding generation times\n",
        "âœ“ Monitor similarity score distributions\n",
        "âœ“ Set up alerts for performance degradation\n",
        "âœ“ Use Azure Monitor for infrastructure metrics\n",
        "\n",
        "## Testing & Validation\n",
        "âœ“ Test with representative data samples\n",
        "âœ“ Validate embedding quality and consistency\n",
        "âœ“ Benchmark different similarity algorithms\n",
        "âœ“ Test error scenarios (connection failures, timeouts)\n",
        "âœ“ Load test with realistic query patterns\n",
        "\"\"\"\n",
        "\n",
        "print(best_practices)\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4a5f69",
      "metadata": {
        "id": "0a4a5f69"
      },
      "source": [
        "## References and Additional Resources\n",
        "\n",
        "### Official Documentation\n",
        "- [Oracle Autonomous Database on Azure](https://www.oracle.com/cloud/azure/)\n",
        "- [cx_Oracle Python Library](https://cx-oracle.readthedocs.io/)\n",
        "- [Sentence Transformers](https://www.sbert.net/)\n",
        "- [Azure Oracle Database@Azure Docs](https://docs.oracle.com/en-us/iaas/Content/Database/Concepts/oracledatabaseathome.htm)\n",
        "\n",
        "### Useful Tutorials\n",
        "- Oracle Database@Azure Setup: [Oracle-Azure Documentation](https://github.com/oracle-devrel/oracle-autonomous-database-samples)\n",
        "- Vector Search Implementation: [Semantic Search Guide](https://huggingface.co/blog/semantic-search-blog)\n",
        "\n",
        "### Related Technologies\n",
        "- Azure Cognitive Search for vector search at scale\n",
        "- Oracle Vector Search (Oracle 23c, 26ai)\n",
        "- Open-source vector databases: Milvus, Weaviate, Pinecone"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
