{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8fa2e6ea",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhusudhanrao-ppm/dbdevrel/blob/main/source-codes/colab-code/similaritysearch/similaritysearch-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4a087b0",
      "metadata": {
        "id": "d4a087b0",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers faiss-cpu oracledb numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d75d5e",
      "metadata": {
        "id": "39d75d5e",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import List, Dict, Optional\n",
        "import numpy as np\n",
        "import oracledb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "def fetch_from_oracle(\n",
        "    table: str = \"MYNOTES\",\n",
        "    column: str = \"NOTES\",\n",
        "    max_rows: int = 1000,\n",
        "    use_wallet: bool = True,\n",
        "    wallet_dir: Optional[str] = None,\n",
        ") -> List[str]:\n",
        "    \"\"\"Fetch text rows from Oracle. Uses env vars ORACLE_USER, ORACLE_PASSWORD, ORACLE_DSN.\n",
        "    If use_wallet=True, provide wallet_dir and wallet_password via env vars.\n",
        "    Returns list of strings (may be empty).\n",
        "    \"\"\"\n",
        "    username = \"DEMOUSER\"  # Update with your username\n",
        "    password = \"YourPassword\"  # Update with your password\n",
        "    tns_name = \"indeducation_high\"\n",
        "    wall_config_dir = \"/content/drive/MyDrive/Wallet_IndEducation\"\n",
        "    wall_pwd = \"walletpassword\"\n",
        "    table = \"MYNOTES\"\n",
        "    col = \"NOTES\"\n",
        "\n",
        "    if not (username and password and tns_name):\n",
        "        print(\"Oracle credentials (ORACLE_USER, ORACLE_PASSWORD, ORACLE_DSN) not set. Returning empty list.\")\n",
        "        return []\n",
        "\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = oracledb.connect(user=username,\n",
        "                              password=password,\n",
        "                              dsn=tns_name,\n",
        "                              config_dir=wall_config_dir,\n",
        "                              wallet_location=wall_config_dir,\n",
        "                              wallet_password=wall_pwd)\n",
        "\n",
        "        # Always use config_dir and wallet_location if wall_config_dir is set,\n",
        "        # as TNS aliases often require it to find tnsnames.ora.\n",
        "\n",
        "        print(\"âœ“ Successfully connected to Oracle Database\")\n",
        "\n",
        "        cur = conn.cursor()\n",
        "        sql = f\"SELECT {column} FROM {table} WHERE {column} IS NOT NULL AND ROWNUM <= :maxrows\"\n",
        "        cur.execute(sql, [max_rows])\n",
        "        rows = cur.fetchall()\n",
        "        texts = [r[0] for r in rows if r and r[0] is not None]\n",
        "        cur.close()\n",
        "        return texts\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching from Oracle: {e}\")\n",
        "        return []\n",
        "    finally:\n",
        "        if conn:\n",
        "            try:\n",
        "                conn.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "def build_embeddings(texts: List[str], model_name: str = MODEL_NAME, batch_size: int = 64):\n",
        "    \"\"\"Return (model, numpy array of embeddings L2-normalized).\"\"\"\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embs = model.encode(texts, batch_size=batch_size, convert_to_numpy=True, show_progress_bar=True)\n",
        "    # normalize\n",
        "    faiss.normalize_L2(embs)\n",
        "    return model, embs\n",
        "\n",
        "def build_faiss_index(embs: np.ndarray):\n",
        "    \"\"\"Create an inner-product index. Inputs should be L2-normalized vectors; inner product == cosine similarity.\"\"\"\n",
        "    dim = embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(embs)\n",
        "    return index\n",
        "\n",
        "def search_index(query: str, model: SentenceTransformer, index: faiss.IndexFlatIP, texts: List[str], k: int = 5):\n",
        "    q_emb = model.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, k)\n",
        "    # D contains inner products (cosine similarity between -1 and 1)\n",
        "    results = []\n",
        "    for score, idx in zip(D[0], I[0]):\n",
        "        if idx < 0:\n",
        "            continue\n",
        "        results.append({\"index\": int(idx), \"text\": texts[idx], \"score\": float(score)})\n",
        "    return results\n",
        "\n",
        "def save_index(path_prefix: str, embs: np.ndarray, texts: List[str]):\n",
        "    np.save(f\"{path_prefix}_emb.npy\", embs)\n",
        "    with open(f\"{path_prefix}_texts.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(texts, f, ensure_ascii=False)\n",
        "\n",
        "def load_index(path_prefix: str):\n",
        "    embs = np.load(f\"{path_prefix}_emb.npy\")\n",
        "    with open(f\"{path_prefix}_texts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        texts = json.load(f)\n",
        "    index = build_faiss_index(embs)\n",
        "    return index, embs, texts\n",
        "\n",
        "\n",
        "# Configuration: switch to True to fetch from Oracle\n",
        "use_oracle = True\n",
        "\n",
        "texts = []\n",
        "if use_oracle:\n",
        "    print(\"Fetching from Oracle...\")\n",
        "    # Note: 'use_wallet=False' was passed here, but the DSN might still implicitly require a config_dir.\n",
        "    # The hardcoded values for Oracle connection parameters inside fetch_from_oracle also need review.\n",
        "    texts = fetch_from_oracle(table=\"MYNOTES\", column=\"NOTES\", max_rows=1000, use_wallet=False)\n",
        "    print(f\"Fetched {len(texts)} rows\")\n",
        "else:\n",
        "    texts = [\n",
        "        \"I want to open an account.\",\n",
        "        \"I want a credit card.\",\n",
        "        \"I need to update my address.\",\n",
        "        \"I want to apply for a loan.\",\n",
        "        \"How do I check my balance?\",\n",
        "        \"I lost my debit card.\"\n",
        "    ]\n",
        "    print(f\"Using {len(texts)} sample texts\")\n",
        "\n",
        "# Build model + embeddings + index\n",
        "model = None # Initialize model to None\n",
        "embs = None # Initialize embs to None\n",
        "index = None # Initialize index to None\n",
        "\n",
        "if texts: # Only build embeddings and index if texts list is not empty\n",
        "    model, embs = build_embeddings(texts)\n",
        "    index = build_faiss_index(embs)\n",
        "    print(\"Index ready. Use search_index(query, model, index, texts, k)\")\n",
        "else:\n",
        "    print(\"No texts available to build embeddings and index.\")\n",
        "    print(\"Please check the Oracle connection details or provide sample texts.\")\n",
        "\n",
        "\n",
        "query = input(\"Enter search query: \")\n",
        "if query.strip():\n",
        "    results = search_index(query, model, index, texts, k=5)\n",
        "    for i, r in enumerate(results, 1):\n",
        "        print(f\"{i}. score={r['score']:.4f}\\n   {r['text'][:300]}\\n\")\n",
        "else:\n",
        "    print(\"No query provided.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
